{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6c8f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, re\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import scipy.io.wavfile as wavfile\n",
    "from scipy.io import loadmat\n",
    "import datetime\n",
    "from parselmouth import Sound\n",
    "from parselmouth.praat import call as pcall\n",
    "from scipy.signal import welch\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Audio\n",
    "\n",
    "from audiolabel import df2tg\n",
    "from phonlab.utils import dir2df, get_timestamp_now\n",
    "from phonlab.array import nonzero_groups\n",
    "\n",
    "import ceti"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c6e5a5",
   "metadata": {},
   "source": [
    "## Locations and params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1a4c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet_id = '1DeQQ-ZDuCumWMz21ouxfJpeSzyRAJykX'\n",
    "sheet_name = 'Sheet1'\n",
    "url = f'https://docs.google.com/spreadsheets/d/{sheet_id}/gviz/tq?tqx=out:csv&sheet={sheet_name}'\n",
    "url = f'https://docs.google.com/spreadsheets/d/1DeQQ-ZDuCumWMz21ouxfJpeSzyRAJykX/gviz/tq?tqx=out:csv&sheet={sheet_name}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29547e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data locations\n",
    "flacdir = Path('/global/scratch/users/rsprouse/datasets/ceti/CETIdata')\n",
    "tgdir = flacdir.parent / 'tg'\n",
    "specdir = flacdir.parent / 'spec'\n",
    "positiondir = Path('/global/scratch/users/rsprouse/datasets/ceti/combined_data')  # Directory of matlab files with position values\n",
    "\n",
    "# Analysis params\n",
    "resample_rate = 120000\n",
    "click_offset = -0.002\n",
    "click_window = 0.015\n",
    "click_window_str = '{}'.format(click_window).lstrip('0')\n",
    "ltas_bw = 100 # Praat 'To Ltas...' bandwidth param\n",
    "praat_spec_fast = False  # Praat 'To Spectrum...' fast param\n",
    "dropIPI = True # If True, drop IPI# columns from google codas spreadsheet\n",
    "conversation_sec = 20 # Max number of seconds between codas in a conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38469d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corrections to Jocasta spreadsheet data\n",
    "jocastabadcodas = [str(n) for n in range(8627, 8671)]\n",
    "jocastaoffset = 0.1537  # Time to subtract from TsTo for codas in `jocastabadcodas`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b99cb98",
   "metadata": {},
   "source": [
    "## Load `.flac` file info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0066b7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "flacdf = ceti.load_flac_info(flacdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cebe5bfd",
   "metadata": {},
   "source": [
    "## Read and merge with codas spreadsheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec1b78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge classifiedCodas spreadsheet with available .flac files in flacdir.\n",
    "# Only codas with matching .flac files are in the result.\n",
    "gsheetdf = ceti.load_classified_codas(\n",
    "    url,\n",
    "    dropIPI=dropIPI,\n",
    "    jocastacorrections={'codas':jocastabadcodas, 'offset': jocastaoffset},\n",
    "    conversation_sec=conversation_sec\n",
    ")\n",
    "clicks = ceti.codadf2clickdf(gsheetdf, 'codaNUM2018', 'TsTo')\n",
    "navalues = {\n",
    "    k: '' for k in \\\n",
    "        ['codaNUM2018', 'Date', 'ELKI2name', 'IDN', 'Name', 'REC', 'Tag', 'TagOnTime', 'Unit']\n",
    "}\n",
    "clicks = flacdf.merge(\n",
    "    clicks,\n",
    "    how='inner',\n",
    "    on='barename'\n",
    ").fillna(navalues)\n",
    "clicks['extract_t1'] = clicks['t1'] - clicks['foffset'] + click_offset\n",
    "clicks['extract_t2'] = clicks['extract_t1'] + click_window\n",
    "# Handle this after removing rows:\n",
    "#clicks['audidx'] = np.arange(len(clicks), dtype=np.int32)  # Row (first dim) location of audio data in ndarray\n",
    "clicks.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8c74eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "clicks.Date.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33a67f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "badclick = clicks['extract_t2'] >= clicks['flacdur']\n",
    "missingcodas = clicks[badclick]\n",
    "#clicks = clicks[~badclick].reset_index(drop=True)\n",
    "print(f\"Removed {badclick.sum()} clicks from {(missingcodas['codaNUM2018'].unique().shape[0])} codas because of bad click times (TsTo > flac file duration).\")\n",
    "clicks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4530055e",
   "metadata": {},
   "outputs": [],
   "source": [
    "clicks.to_csv('clicks.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2927c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "suspect = (clicks['extract_t1'] <= 0) | (clicks['extract_t2'] >= clicks['flacdur'])\n",
    "print(clicks[suspect]['TagOnTime'].unique())\n",
    "print(clicks[suspect]['Tag'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9fa454d",
   "metadata": {},
   "outputs": [],
   "source": [
    "clicks[suspect & (clicks['TagOnTime'] == '07:57:09')]['codaNUM2018'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8165d967",
   "metadata": {},
   "source": [
    "## Add behavioral metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f8c600",
   "metadata": {},
   "outputs": [],
   "source": [
    "bhvspreadsheet_id = '1WjwPJWWhS-7S2WiyA8buoWts8RNRN0-mHDzAIg4efxc'\n",
    "bhvurl = f'https://docs.google.com/spreadsheets/d/{bhvspreadsheet_id}/export?format=csv'\n",
    "bhvdf = pd.read_csv(bhvurl)\n",
    "bhvdf['bhvdt'] = pd.to_datetime(\n",
    "    bhvdf['date'].astype(str) + 'T' + bhvdf['time'],\n",
    "    format='%Y%m%dT%H:%M'\n",
    ")\n",
    "#bhvdf['bhvdt.copy'] = bhvdf['bhvdt'].copy()\n",
    "# Drop incomplete rows and sort by datetime\n",
    "bhvdf = bhvdf.dropna(how='any', subset=['bhvdt', 'behavior'])\n",
    "bhvdf = bhvdf.sort_values('bhvdt')\n",
    "bhvdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a33627",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop incomplete rows and sort by datetime\n",
    "nocodadt = clicks[clicks['codadt'].isna()].copy()\n",
    "clicks = clicks.dropna(how='any', subset='codadt')\n",
    "clicks = clicks.sort_values('codadt')\n",
    "for direction, sfx in (('backward', 'bkwd'), ('forward', 'fwd'), ('nearest', 'near')):\n",
    "    clicks = pd.merge_asof(\n",
    "        clicks,\n",
    "        bhvdf[['bhvdt', 'behavior']],\n",
    "        left_on='codadt',\n",
    "        right_on='bhvdt',\n",
    "        suffixes=('', f'_{sfx}'),\n",
    "        tolerance=pd.Timedelta('1 hour'),\n",
    "        direction=direction\n",
    "    ).rename({'bhvdt': f'bhvdt_{sfx}', 'behavior': f'bhv_{sfx}'}, axis='columns')\n",
    "\n",
    "# Add back incomplete rows\n",
    "clicks = pd.concat([clicks, nocodadt], axis='rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b6193e",
   "metadata": {},
   "outputs": [],
   "source": [
    "(clicks['bhvdt_near'] - clicks['codadt']).dt.components[['minutes', 'seconds']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6fbd466",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: also check aws for new tag data and process\n",
    "def summarize_behavior(g):\n",
    "    return g.iloc[0]\n",
    "myc = clicks[~clicks['bhvdt_bkwd'].isna()][['codaNUM2018', 'codadt', 'bhvdt_bkwd', 'bhv_bkwd', 'bhvdt_fwd', 'bhv_fwd', 'bhvdt_near', 'bhv_near']].groupby('codaNUM2018').apply(summarize_behavior, include_groups=False)\n",
    "myc.to_csv('allcodas-behavior.csv', index=True)\n",
    "myc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5f7848",
   "metadata": {},
   "source": [
    "## Add position data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9bd7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dprhdf = dir2df(positiondir, fnpat='(?P<tag>.+)\\.dprh\\.wav$')\n",
    "dprhdf['posabspath'] = positiondir / dprhdf['relpath'].astype(str) / dprhdf['fname'].astype(str)\n",
    "try:\n",
    "    assert(~dprhdf['tag'].duplicated().any())\n",
    "except AssertionError:\n",
    "    print('Found duplicate tag values.')\n",
    "dprhdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83eeaa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't execute this unless needed. It is a memory hog.\n",
    "if False:\n",
    "    y = get_positions_from_tag_times(dprhdf, tag='sw143a', t1=0.5, t2=5.0, chanstr='dp', resample_rate=120000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65aad3bd",
   "metadata": {},
   "source": [
    "## Extract click audio\n",
    "\n",
    "Make a 3d ndarray of click audio. Dimensions: `click (coda + clicknum), channel (left|right), samples`.\n",
    "\n",
    "Normalize by removing DC offset and scaling peak magnitude to 1.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fdd463c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by audio file and coda for fewer IO open operations. Add a zero-based column that can\n",
    "# be used to match rows (first dimension) of extracted audio ndarray.\n",
    "clicks = clicks.sort_values(['Tag', 'codaNUM2018']).reset_index(drop=True).reset_index(names='audidx')\n",
    "#clicks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a396541e",
   "metadata": {},
   "outputs": [],
   "source": [
    "clickaudio = ceti.extract_click_audio(\n",
    "    clicks, 'codaNUM2018', 't1', click_offset, click_window, flacdir, resample_rate, 'Tag'\n",
    ")\n",
    "clickaudio = ceti.normalize_audio(clickaudio, remdc=True, peak_scale=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26cbd116",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(~np.isnan(clickaudio).any())\n",
    "clickaudio.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94795305",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(clicks[clicks['audidx'] == 420])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad9025d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(clicks[(clicks['codaNUM2018'] == '5031') & (clicks['clicknum'] == 1)])\n",
    "plt.plot(clickaudio[420, 0, :300]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd2e30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "clicks[(clicks['codaNUM2018'] == '5031')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870fa693",
   "metadata": {},
   "source": [
    "### Make sure clickaudio matches clicks dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2207b734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly test a number of audio clicks to make sure they appear in the proper order\n",
    "# in `clickaudio`.\n",
    "ntest = 1000\n",
    "for row in clicks.sample(ntest).itertuples():\n",
    "    aufile = Path(flacdir) / row.relpath / f\"{row.Tag}.flac\"\n",
    "    randaud = ceti.get_single_click_audio(aufile, row.t1, click_offset, click_window, resample_rate, verbose=False)\n",
    "    randaud = ceti.normalize_audio(randaud, remdc=True, peak_scale=None)\n",
    "    assert((clickaudio[row.Index] == randaud).all())\n",
    "print('SUCCESS')\n",
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132f3808",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 420\n",
    "chan = 0\n",
    "rng = np.arange(0, 500)\n",
    "row = clicks.iloc[idx]\n",
    "aufile = Path(flacdir) / row['relpath'] / f\"{row['Tag']}.flac\"\n",
    "print(aufile)\n",
    "randaud = ceti.get_single_click_audio(aufile, row['t1'], click_offset, click_window, resample_rate)\n",
    "print(f'Got {randaud.shape} from {aufile}')\n",
    "mu = randaud.mean(axis=-1, keepdims=True)\n",
    "randaud -= mu # Remove DC offset\n",
    "#randaud /= np.abs(randaud).max(axis=-1, keepdims=True) * 1.0  # Normalize max magnitude to 0.99\n",
    "try:\n",
    "    assert((clickaudio[idx, chan, :] == randaud[chan, :]).all())\n",
    "    print('SUCCESS: samples match')\n",
    "except AssertionError:\n",
    "    print('ERROR: samples do not match')\n",
    "fig, axs = plt.subplots(2, figsize=[10, 8])\n",
    "axs[0].plot(clickaudio[idx, chan, rng])\n",
    "axs[1].plot(randaud[chan, rng]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e1e21e",
   "metadata": {},
   "source": [
    "## Concatenate and save all audio and corresponding to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7b5add",
   "metadata": {},
   "outputs": [],
   "source": [
    "tstamp = get_timestamp_now()[0]\n",
    "print(tstamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9ef067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all extracted audio as 'unscaled' and 'pknorm'.\n",
    "for s, saudio in (('unscaled', clickaudio), ('pknorm', ceti.normalize_audio(clickaudio.copy(), remdc=False, peak_scale=1.0))):\n",
    "    for chanidx, chanstr in enumerate(('left', 'right')):\n",
    "        outfile = flacdir.parent / f'allclicks.{chanstr}.{tstamp}.{s}.{saudio.shape[-1]}samples.wav'\n",
    "        wavfile.write(outfile, resample_rate, saudio[:,chanidx,:].ravel())\n",
    "#        sf.write(outfile, clickaudio[:,chanidx,:].ravel(), resample_rate) # This seems to scale audio\n",
    "        print(outfile)\n",
    "\n",
    "# Save click dataframe. The `audidx` column matches dataframe rows to\n",
    "# its sequence in the audio file.\n",
    "csvout = flacdir.parent / f'allclicks.{tstamp}.csv'\n",
    "clicks.to_csv(csvout, index=False)\n",
    "print(csvout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e628e407",
   "metadata": {},
   "outputs": [],
   "source": [
    "tstamp, outfile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2360ffe6",
   "metadata": {},
   "source": [
    "### Concatenate and save a subset of extracted audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c0294a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get desired subset of clicks and matching audio\n",
    "mydf = clicks[clicks['Focal'] == 1].copy()\n",
    "selaudio = clickaudio[mydf.index]\n",
    "selaudio2 = clickaudio[clicks[clicks['Focal'] == 1]['audidx']]\n",
    "selaudio3 = clickaudio[mydf.sort_values('TagOnTime').reset_index(drop=True).index]\n",
    "selaudio4 = clickaudio[clicks.sort_values('TagOnTime').reset_index(drop=True)[clicks['Focal'] == 1]['audidx']]\n",
    "assert(mydf.shape[0] == selaudio.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669f2efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "clicks[clicks['Focal'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4b44ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "clicks[clicks['Focal'] == 1][['audidx', 'Focal', 'tag', 'TsTo', 'TagOnTime']].sort_values('TagOnTime').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a86cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "clicks[clicks['Focal'] == 1].sort_values('TagOnTime').reset_index(drop=True)[['audidx', 'Focal', 'tag', 'TsTo', 'TagOnTime']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61823e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "(selaudio == selaudio4).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92545851",
   "metadata": {},
   "outputs": [],
   "source": [
    "selaudio.shape == selaudio4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3496cb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(selaudio[47, 0, :300]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae62cb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(selaudio4[47, 0, :300]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d51bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mydf.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb16157",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now reset index to zero-based to match selaudio\n",
    "mydf = mydf.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f758c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "mydf.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63fa1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mydf[(mydf['codaNUM2018'] == '5031')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc62af62",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(clickaudio[420, 0, :300]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f5d172",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(selaudio[275, 0, :300]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c5a675",
   "metadata": {},
   "outputs": [],
   "source": [
    "# And sort as desired. The index will be used to select first dim of selaudio.\n",
    "mydf = mydf.sort_values(['Name', 'codaNUM2018', 'clicknum'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fefb1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mydf.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38104209",
   "metadata": {},
   "outputs": [],
   "source": [
    "mydf[(mydf['codaNUM2018'] == '5031')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e528a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(selaudio[1422, 1, :350]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db377331",
   "metadata": {},
   "outputs": [],
   "source": [
    "mydf.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8866de74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally save the audio\n",
    "saveaudio = selaudio[mydf.index]\n",
    "tstamp = get_timestamp_now()[0]\n",
    "leftout = specdir.parent / f'clicks.focal.left.{tstamp}.wav'\n",
    "rightout = specdir.parent / f'clicks.focal.right.{tstamp}.wav'\n",
    "sf.write(leftout, saveaudio[:,0,:].ravel(), resample_rate)\n",
    "sf.write(rightout, saveaudio[:,1,:].ravel(), resample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58464bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(saveaudio[275,0,:350])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0b9913",
   "metadata": {},
   "source": [
    "### Create and save associated textgrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0084cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "mydf = mydf.reset_index(drop=True)\n",
    "mydf #.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39458b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "codadf[codadf['text'] == '5031']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed195ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "mydf = codadf.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae4b480",
   "metadata": {},
   "outputs": [],
   "source": [
    "whaledf = pd.DataFrame({\n",
    "    'text': mydf[~mydf['Name'].duplicated()]['Name'],\n",
    "    't1': mydf[~mydf['Name'].duplicated()].index * click_window,\n",
    "    't2': mydf[~mydf['Name'].duplicated(keep='last')].index * click_window + click_window\n",
    "})\n",
    "whaledf\n",
    "\n",
    "codadf = pd.DataFrame({\n",
    "    'text': mydf[~mydf['codaNUM2018'].duplicated()]['codaNUM2018'],\n",
    "    't1': mydf[~mydf['codaNUM2018'].duplicated()].index * click_window,\n",
    "    't2': mydf[~mydf['codaNUM2018'].duplicated(keep='last')].index * click_window + click_window\n",
    "})\n",
    "codadf\n",
    "\n",
    "clickdf = pd.DataFrame({\n",
    "    'text': mydf['clicknum'].astype(str),\n",
    "    't1': mydf.index * click_window,\n",
    "    't2': mydf.index * click_window + click_window\n",
    "})\n",
    "clickdf\n",
    "\n",
    "clicktg = df2tg(\n",
    "    [whaledf, codadf, clickdf],\n",
    "    tnames=['whale', 'coda', 'clicknum'],\n",
    "    lbl='text',\n",
    "    fmt='0.4f',\n",
    "    fill_gaps=None,\n",
    "    outfile=specdir.parent / f'clicks.focal.{tstamp}.TextGrid'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80751351",
   "metadata": {},
   "source": [
    "## Spectral analysis with `scipy.welch`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d59a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "welchfreqs, wspec = welch(clickaudio, fs=resample_rate, nperseg=clickaudio.shape[-1]) #, window='boxcar')\n",
    "welchfreqcols = [f'Hz{f}' for f in np.round(welchfreqs).astype(int)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153588a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 1147\n",
    "fig, axs = plt.subplots(3, 2, figsize=[10, 8]);\n",
    "axs[0, 0].plot(clickaudio[idx,0,:]);\n",
    "axs[0, 1].plot(clickaudio[idx,1,:]);\n",
    "axs[1, 0].plot(welchfreqs, wspec[idx,0]);\n",
    "axs[1, 1].plot(welchfreqs, wspec[idx,1]);\n",
    "axs[2, 0].plot(welchfreqs, 10*np.log10(wspec[idx,0]/2e-5));\n",
    "axs[2, 1].plot(welchfreqs, 10*np.log10(wspec[idx,1]/2e-5));\n",
    "audbit = Audio(data=clickaudio[idx], rate=resample_rate)\n",
    "display(audbit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c379c42",
   "metadata": {},
   "source": [
    "### Combine metadata with spectral analysis and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09da6a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "subdf = clicks.head(6)\n",
    "subdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6228e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "wspecleftdf = pd.DataFrame(wspec[:, 0], columns=welchfreqcols)\n",
    "wspecleftdf.head(6).T.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb536fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that allcodas matches wspec (same length and increments from zero)\n",
    "assert(clicks.shape[0] == wspec.shape[0])\n",
    "assert(clicks.index.start == 0)\n",
    "assert(clicks.index.stop == wspec.shape[0])\n",
    "clicksfreqswide = pd.merge(\n",
    "    clicks,\n",
    "    pd.DataFrame(wspec[:, 0], columns=welchfreqcols),\n",
    "    how='inner',\n",
    "    left_index=True,\n",
    "    right_index=True\n",
    ")\n",
    "# There must be a matching frequency analysis for every coda-click in allcodas\n",
    "assert(clicks.shape[0] == clicksfreqswide.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db801f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "clicksfreqslong = pd.wide_to_long(\n",
    "    clicksfreqswide,\n",
    "    stubnames='Hz',\n",
    "    i=('codaNUM2018', 'clicknum'),\n",
    "    j='binHz'\n",
    ") \\\n",
    ".rename({'Hz': 'wspec'}, axis='columns') \\\n",
    ".reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57f095b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify that shape of result is as expected (bin frequency columns converted to rows for each coda-click)\n",
    "# (The +2 accounts for the ('codaNUM2018', 'clicknum') columns.)\n",
    "assert(\n",
    "    (clicksfreqswide.shape[1] - clicksfreqslong.shape[1] + 2) * clicksfreqswide.shape[0] == clicksfreqslong.shape[0]\n",
    ")\n",
    "clicksfreqswide.shape, clicksfreqslong.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dadb26da",
   "metadata": {},
   "outputs": [],
   "source": [
    "tstampfreq = get_timestamp_now()[0]\n",
    "clicksfreqswide.to_csv(specdir / f'clicks.welch.wide.{tstampfreq}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83248775",
   "metadata": {},
   "outputs": [],
   "source": [
    "clicksfreqslong.to_csv(specdir / f'clicks.welch.long.{tstampfreq}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf10d624",
   "metadata": {},
   "source": [
    "### Read from `.csv` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec69c08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "widecachedf = pd.read_csv(specdir / f'clicks.welch.wide.{tstampfreq}.csv')\n",
    "widecachedf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2ba932",
   "metadata": {},
   "outputs": [],
   "source": [
    "specdir / f'clicks.welch.wide.{tstampfreq}.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0141deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "longcachedf = pd.read_csv(specdir / 'clicks.welch.long.20231010.csv')\n",
    "longcachedf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802ac042",
   "metadata": {},
   "source": [
    "## Extract coda audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe02940",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_coda_audio(clickdf, codacol, t1col, click_offset, click_window,\n",
    "    audiodir, resample_rate, groupby, pad):\n",
    "    '''\n",
    "    Extract audio chunks for each coda in a dataframe.\n",
    "    \n",
    "    For better IO performance reads are grouped by audio file, indicated by\n",
    "    the `groupby` param.\n",
    "    '''\n",
    "    audio = {}\n",
    "    for _, audf in clickdf.groupby(groupby):\n",
    "        aufile = Path(audiodir) / \\\n",
    "                 audf.iloc[0]['relpath'] / \\\n",
    "                 f\"{audf.iloc[0][groupby]}{audf.iloc[0]['ext']}\"\n",
    "        with sf.SoundFile(aufile, 'r') as fh:\n",
    "            sr_native = fh.samplerate\n",
    "            if sr_native < resample_rate:\n",
    "                sys.stderr.write(\n",
    "                    f'WARNING: Upsampling {aufile} from {sr_native} to {resample_rate}.\\n'\n",
    "                )\n",
    "            for __, cdf in audf.groupby(codacol):\n",
    "                t1 = cdf['t1'].min() + click_offset - pad\n",
    "                t2 = cdf['t1'].max() + click_offset + click_window + pad\n",
    "                nsamp = np.round((t2 - t1) * sr_native).astype(int)\n",
    "                try:\n",
    "                    fh.seek(np.round((t1 + click_offset) * sr_native).astype(int))\n",
    "                    # Load the target number of frames, and transpose to match librosa form\n",
    "                    y = fh.read(frames=nsamp, dtype=np.float32, always_2d=False).T\n",
    "                    if sr_native != resample_rate:\n",
    "                        y = librosa.resample(\n",
    "                            y, orig_sr=sr_native, target_sr=resample_rate\n",
    "                        )\n",
    "                    audio[cdf['codaNUM2018'].iloc[0]] = {'audio': y, 'clicks': cdf, 't1': t1, 'nsamp': nsamp, 'pad': pad}\n",
    "                except Exception as e:\n",
    "                    sys.stderr.write(e)\n",
    "                    break\n",
    "    return audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decd242d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pad = 0.200\n",
    "codaaudio = extract_coda_audio(\n",
    "    clicks, 'codaNUM2018', 't1', click_offset, click_window, flacdir, resample_rate, 'Tag', pad\n",
    ")\n",
    "#clickaudio = ceti.normalize_audio(clickaudio, remdc=True, peak_scale=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ab80da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "codaoutfile = specdir.parent / 'codaaudio.pyc'\n",
    "with open(codaoutfile, 'wb') as codafh:\n",
    "    pickle.dump(codaaudio, codafh)\n",
    "print(codaoutfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8cc0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(codaaudio['4933']['audio'][0,:]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e37d32b",
   "metadata": {},
   "source": [
    "## Conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fca9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "convocols = ['Tag', 'codaNUM2018', 'clicknum', 'Date', 'TagOnTime', 'TsTo', 'codadt', 'Name', 'convo', 'convoN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8828dbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "monologdf = clicks[clicks['convoN'] == 1].copy()\n",
    "multilogdf = clicks[clicks['convoN'] > 1].copy()\n",
    "monologdf['convo'].unique(), multilogdf['convo'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359ee586",
   "metadata": {},
   "outputs": [],
   "source": [
    "multilogdf['Date'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ff2897",
   "metadata": {},
   "outputs": [],
   "source": [
    "multilogdf[multilogdf['convo'] == 27][convocols].sort_values(['codadt', 'clicknum']).head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6afe32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_convo_audio_old(convodf, audiodir, resample_rate, convopad):\n",
    "    '''\n",
    "    Extract audio tracks for a conversation.\n",
    "    \n",
    "    '''\n",
    "    audio = []\n",
    "    sampcnts = set()\n",
    "    for g in convodf.groupby('convo'):\n",
    "        g[1]['Date'] = pd.to_datetime(g[1]['Date'], format='%Y-%m-%d 00:00:00')\n",
    "        g[1]['TagOnTime'] = pd.to_timedelta(g[1]['TagOnTime'])\n",
    "        g[1]['flac_t1'] = g[1]['Date'] + g[1]['TagOnTime']  # Start datetime of .flac file.\n",
    "        g[1]['convot1'] = (g[1]['codadt'].min() - convopad - g[1]['flac_t1']).dt.total_seconds()\n",
    "        g[1]['convot2'] = (g[1]['codadt'].max() + convopad - g[1]['flac_t1']).dt.total_seconds()\n",
    "        for tg in g[1].groupby('tag'):\n",
    "            convot1 = tg[1]['convot1'].iloc[0]\n",
    "            convot2 = tg[1]['convot2'].iloc[0]\n",
    "            aufile = Path(audiodir) / \\\n",
    "                tg[1]['relpath'].iloc[0] / \\\n",
    "                tg[1]['fname'].iloc[0]\n",
    "            with sf.SoundFile(aufile, 'r') as fh:\n",
    "                sr_native = fh.samplerate\n",
    "                if sr_native < resample_rate:\n",
    "                    sys.stderr.write(\n",
    "                        f'WARNING: Upsampling {aufile} from {sr_native} to {resample_rate} Hz.\\n'\n",
    "                    )\n",
    "                nsamp = int((convot2 - convot1) * sr_native)\n",
    "                sampcnts.add(nsamp)\n",
    "                try:\n",
    "                    fh.seek(int(convot1 * sr_native))\n",
    "                    # Load the target number of frames, and transpose to match librosa form\n",
    "                    y = fh.read(frames=nsamp, dtype=np.float32, always_2d=False).T\n",
    "                    if sr_native != resample_rate:\n",
    "                        y = librosa.resample(\n",
    "                            y, orig_sr=sr_native, target_sr=resample_rate\n",
    "                        )\n",
    "                    audio.append(y)\n",
    "                except Exception as e:\n",
    "                    sys.stderr.write(f'Could not read {aufile} from {convot1} to {convot2}: {e}')\n",
    "    # Make sure arrays are the same length, just in case durations are slightly different.\n",
    "    sampcnts = np.array(list(sampcnts))\n",
    "    padto = sampcnts.max()\n",
    "    for i, a in enumerate(audio):\n",
    "        if a.shape[-1] < padto:\n",
    "            if len(a.shape) == 2:\n",
    "                audio[i] = np.pad(a, pad_width=((0, 0), (0, padto - a.shape[-1])))\n",
    "            elif len(a.shape) == 1:\n",
    "                audio[i] = np.pad(a, pad_width=(0, padto - a.shape[-1]))\n",
    "            else:\n",
    "                sys.stderr.write(f'Padding of audio with more than two channels not implemented.\\n')\n",
    "    try:\n",
    "        audio = np.array(audio)\n",
    "        audio = np.reshape(audio, (-1, audio.shape[-1]))\n",
    "    except:\n",
    "        pass\n",
    "    return audio, sampcnts\n",
    "\n",
    "def combine_overlaps(df):\n",
    "    '''\n",
    "    Find dataframe rows that overlap in time and combine them, dropping\n",
    "    original rows\n",
    "    '''\n",
    "    df = pd.concat(\n",
    "        [\n",
    "            df,\n",
    "            pd.DataFrame({\n",
    "                'overlaps_following': (df['t1'].shift(-1) < df['t2']).iloc[:-1]\n",
    "            }, index=df['t2'].index)\n",
    "        ], axis='columns')\n",
    "    df['is_overlapped'] = df['overlaps_following'].shift(1)\n",
    "    overlapidx = df[df['overlaps_following'] | df['is_overlapped']].index\n",
    "    dfs = [df]\n",
    "    for i0, i1 in (zip(overlapidx[::2], overlapidx[1::2])):\n",
    "        dfs.append(\n",
    "            pd.DataFrame({\n",
    "                'codaNUM2018': [df.loc[i0, 'codaNUM2018']][0] + '/' + \\\n",
    "                               [df.loc[i1, 'codaNUM2018']][0],\n",
    "                't1': min([df.loc[i0, 't1'], df.loc[i1, 't1']]),\n",
    "                't2': max([df.loc[i0, 't2'], df.loc[i1, 't2']]),\n",
    "                'text': [df.loc[i1, 'text']][0]                        \n",
    "            }, index=[-1])\n",
    "        )\n",
    "    df = pd.concat(dfs, axis='rows')\n",
    "    df = df.drop(overlapidx).sort_values('t1')\n",
    "    return df\n",
    "\n",
    "def extract_convo_audio(convodf, audiodir, resample_rate, convopad, dprhdf):\n",
    "    '''\n",
    "    Extract audio tracks for a conversation.\n",
    "    \n",
    "    '''\n",
    "    audio = []\n",
    "    sampcnts = set()\n",
    "    convodf['Date'] = pd.to_datetime(g[1]['Date'], format='%Y-%m-%d 00:00:00')\n",
    "    convodf['TagOnTime'] = pd.to_timedelta(g[1]['TagOnTime'])\n",
    "    convodf['flac_t1'] = convodf['Date'] + g[1]['TagOnTime']  # Start datetime of .flac file.\n",
    "    convodf['convot1'] = (\n",
    "        convodf['codadt'].min() - convopad - convodf['flac_t1']\n",
    "    ).dt.total_seconds()\n",
    "    convodf['convot2'] = (\n",
    "        convodf['codadt'].max() + convopad - convodf['flac_t1']\n",
    "    ).dt.total_seconds()\n",
    "    tiers = {}\n",
    "    for tieridx, tg in enumerate(convodf.groupby(['tag', 'Focal'])):\n",
    "        is_focal = tg[0][1] == 1\n",
    "        tgdf = tg[1].sort_values('extract_t1').copy()\n",
    "        convot1 = tgdf['convot1'].iloc[0]\n",
    "        convot2 = tgdf['convot2'].iloc[0]\n",
    "        aufile = Path(audiodir) / \\\n",
    "            tgdf['relpath'].iloc[0] / \\\n",
    "            tgdf['fname'].iloc[0]\n",
    "        with sf.SoundFile(aufile, 'r') as fh:\n",
    "            sr_native = fh.samplerate\n",
    "            if sr_native < resample_rate:\n",
    "                sys.stderr.write(\n",
    "                    f'WARNING: Upsampling {aufile} from {sr_native} to {resample_rate} Hz.\\n'\n",
    "                )\n",
    "            nsamp = int((convot2 - convot1) * sr_native)\n",
    "            sampcnts.add(nsamp)\n",
    "            try:\n",
    "                fh.seek(int(convot1 * sr_native))\n",
    "                # Load the target number of frames, and transpose to match librosa form\n",
    "                y = fh.read(frames=nsamp, dtype=np.float32, always_2d=False).T\n",
    "                if sr_native != resample_rate:\n",
    "                    y = librosa.resample(\n",
    "                        y, orig_sr=sr_native, target_sr=resample_rate\n",
    "                    )\n",
    "                audio.append(y)\n",
    "            except Exception as e:\n",
    "                sys.stderr.write(f'Could not read {aufile} from {convot1} to {convot2}: {e}')\n",
    "        # Extract depth. Some artifacts appear at the edges because of extreme upsampling.\n",
    "        try:\n",
    "            depth = ceti.get_positions_from_tag_times(\n",
    "                dprhdf,\n",
    "                tag=tg[1].iloc[0]['tag'],\n",
    "                t1=convot1,\n",
    "                t2=convot2,\n",
    "                chanstr='d',\n",
    "                resample_rate=resample_rate\n",
    "            )\n",
    "        except Exception as e:\n",
    "            depth = None\n",
    "            sys.stderr.write(\n",
    "                f\"Could not add depth for tag {tg[1].iloc[0]['tag']} from {convot1} to {convot2}: {e}\"\n",
    "            )\n",
    "        # Make textgrid tier for tag\n",
    "        tagcodadf = \\\n",
    "            tgdf[['codaNUM2018', 'extract_t1']].groupby('codaNUM2018').apply(np.minimum.reduce, include_groups=False).join(\n",
    "            [\n",
    "                tgdf[['codaNUM2018', 'extract_t2']].groupby('codaNUM2018').apply(np.maximum.reduce, include_groups=False),\n",
    "                tgdf[['codaNUM2018', 'bhv_bkwd', 'bhv_fwd', 'bhv_near']].fillna('').groupby('codaNUM2018').apply(lambda x: x.agg(\";\".join, axis='columns').iloc[0], include_groups=False)\n",
    "            ]\n",
    "        ).reset_index().rename({'extract_t1': 't1', 'extract_t2': 't2', 0: 'text'}, axis='columns')\n",
    "        tagcodadf[['t1', 't2']] -= convot1\n",
    "        tagcodadf = combine_overlaps(tagcodadf.sort_values('t1'))\n",
    "        tagcodadf['text'] = tagcodadf['codaNUM2018'] + '\\n' + tagcodadf['text']\n",
    "        tiername = tgdf['Name'].iloc[0] if is_focal else f'nonfocal{tieridx}'\n",
    "        tiers[tiername] = tagcodadf\n",
    "    # Make sure arrays are the same length, just in case durations are slightly different.\n",
    "    sampcnts = np.array(list(sampcnts))\n",
    "    padto = sampcnts.max()\n",
    "    for i, a in enumerate(audio):\n",
    "        if a.shape[-1] < padto:\n",
    "            if len(a.shape) == 2:\n",
    "                audio[i] = np.pad(a, pad_width=((0, 0), (0, padto - a.shape[-1])))\n",
    "            elif len(a.shape) == 1:\n",
    "                audio[i] = np.pad(a, pad_width=(0, padto - a.shape[-1]))\n",
    "            else:\n",
    "                sys.stderr.write(f'Padding of audio with more than two channels not implemented.\\n')\n",
    "    try:\n",
    "        audio = np.array(audio)\n",
    "        audio = np.reshape(audio, (-1, audio.shape[-1]))\n",
    "    except:\n",
    "        pass\n",
    "    if depth is not None:\n",
    "        # Append depth as last channel of audio.\n",
    "        if depth.shape[1] > audio.shape[1]:\n",
    "            lefttrim = np.round((depth.shape[1] - audio.shape[1]) / 2).astype(int)\n",
    "            righttrim = (lefttrim + (depth.shape[1] - audio.shape[1]) % 2) * -1\n",
    "            depth = depth[:, lefttrim:righttrim]\n",
    "        elif depth.shape[1] < audio.shape[1]:\n",
    "            leftpad = np.round((audio.shape[1] - depth.shape[1]) / 2).astype(int)\n",
    "            rightpad = leftpad - (audio.shape[1] - depth.shape[1]) % 2\n",
    "            depth = np.pad(depth, ((0,0), (leftpad, rightpad)), mode='edge')\n",
    "        try:\n",
    "            audio = np.vstack((audio, depth))\n",
    "        except:\n",
    "            sys.stderr.write(f'Did not vstack {audio.shape} {depth.shape}')\n",
    "    return audio, sampcnts, convodf, tiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802afd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debugging cell\n",
    "convodf\n",
    "tiers = {}\n",
    "for tg in convodf.groupby('tag'):\n",
    "        tgdf = tg[1].sort_values('extract_t1').copy()\n",
    "        convot1 = tgdf['convot1'].iloc[0]\n",
    "        convot2 = tgdf['convot2'].iloc[0]\n",
    "        tagcodadf = \\\n",
    "            tgdf[['codaNUM2018', 'extract_t1']].groupby('codaNUM2018').apply(np.minimum.reduce, include_groups=False).join(\n",
    "            [\n",
    "                tgdf[['codaNUM2018', 'extract_t2']].groupby('codaNUM2018').apply(np.maximum.reduce, include_groups=False),\n",
    "                tgdf[['codaNUM2018', 'bhv_bkwd', 'bhv_fwd', 'bhv_near']].fillna('').groupby('codaNUM2018').apply(lambda x: x.agg(\";\".join, axis='columns').iloc[0], include_groups=False)\n",
    "            ]\n",
    "        ).reset_index().rename({'extract_t1': 't1', 'extract_t2': 't2', 0: 'text'}, axis='columns')\n",
    "        tagcodadf[['t1', 't2']] -= convot1\n",
    "        tagcodadf = combine_overlaps(tagcodadf.sort_values('t1'))\n",
    "        tagcodadf['text'] = tagcodadf['codaNUM2018'] + '\\n' + tagcodadf['text']\n",
    "        tiers[tgdf['Name'].iloc[0]] = tagcodadf\n",
    "tagcodadf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f89d41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(audio[5,:]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3d87c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm /global/scratch/users/rsprouse/datasets/ceti/convo/*.wav\n",
    "!rm /global/scratch/users/rsprouse/datasets/ceti/convo/*.TextGrid\n",
    "\n",
    "tstamp = get_timestamp_now()[0]\n",
    "for g in multilogdf.groupby('convo'):\n",
    "    convopad = pd.to_timedelta(60, unit='seconds')\n",
    "    g[1].loc[:, ['bhv_bkwd', 'bhv_fwd', 'bhv_near']].fillna('', inplace=True)\n",
    "    audio, sampcnts, convodf, tiers = extract_convo_audio(g[1], flacdir, resample_rate, convopad, dprhdf)\n",
    "    outfile = specdir.parent / 'convo' / f\"convo.{g[1]['barename'].iloc[0]}.{g[1]['convo'].iloc[0]}.{g[1]['TsTo'].iloc[0]}.{tstamp}.wav\"\n",
    "    sf.write(outfile, audio.T, resample_rate)\n",
    "    print(f'Wrote {outfile}')\n",
    "    try:\n",
    "        clicktg = df2tg(\n",
    "            list(tiers.values()),\n",
    "            tnames=list(tiers.keys()),\n",
    "            lbl='text',\n",
    "            fmt='0.4f',\n",
    "            start=0.0,\n",
    "            end=audio.shape[1] / resample_rate,\n",
    "            outfile=outfile.with_suffix('.TextGrid')\n",
    "        )\n",
    "        print(f\"Wrote {outfile.with_suffix('.TextGrid')}\")\n",
    "    except Exception as e:\n",
    "        sys.stderr.write(f'{e}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7202c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "convopad = pd.to_timedelta(60, unit='seconds')\n",
    "for g in multilogdf.groupby('convo'):\n",
    "    g[1]['Date'] = pd.to_datetime(g[1]['Date'], format='%Y-%m-%d 00:00:00')\n",
    "    g[1]['TagOnTime'] = pd.to_timedelta(g[1]['TagOnTime'])\n",
    "    g[1]['flac_t1'] = g[1]['Date'] + g[1]['TagOnTime']  # Start datetime of .flac file.\n",
    "    g[1]['convot1'] = (g[1]['codadt'].min() - convopad - g[1]['flac_t1']).dt.total_seconds()\n",
    "    g[1]['convot2'] = (g[1]['codadt'].max() + convopad - g[1]['flac_t1']).dt.total_seconds()\n",
    "    for tg in g[1].groupby('tag'):\n",
    "        flacpath = flacdir / tg[1]['relpath'].iloc[0] / tg[1]['fname'].iloc[0]\n",
    "        print(f\"{flacpath}: {tg[1]['convot1'].iloc[0]}:{tg[1]['convot2'].iloc[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb08538d",
   "metadata": {},
   "outputs": [],
   "source": [
    "2061.77 - 1915.7594, 191.77 - 45.7594"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ab54a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[convocols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1ccc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[convocols]\n",
    "#df['Date'] + df['TagOnTime'] + df['TsTo']\n",
    "(t1 - df['rec_t1']).dt.total_seconds().iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa0b13f",
   "metadata": {},
   "source": [
    "## Birth event\n",
    "\n",
    "Birth event recorded 20230708. Raw recordings copied from CETI AWS S3 bucket `ceti-data`, path `raw/2023-07-08`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab138bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data locations\n",
    "birthdir = Path('/global/scratch/users/rsprouse/datasets/ceti/birth_event')\n",
    "birthspecdir = flacdir.parent / 'spec'\n",
    "birthcsv = birthdir / 'Haifa_annotations_updated.csv'\n",
    "birthbehavxlsx = birthdir / 'Preliminary behavioural annotations of Drone Video from Shane.xlsx'\n",
    "birthresample_rate = 48000 # Original recording seems to be 48KHz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a58890",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochwavdf = dir2df(birthdir, fnpat='^(?P<barename>CETI\\d+-\\d+)\\.(?P<wavepoch>\\d+)(_\\d+)?\\.wav$', addcols=['ext'])\n",
    "epochwavdf = epochwavdf.groupby(['barename', 'wavepoch'], observed=True).size().reset_index().drop(0, axis='columns')\n",
    "epochwavdf['wavdatetime'] = pd.to_datetime(epochwavdf['wavepoch'].astype(int), unit='ms')\n",
    "#epochwavdf['codadt'] = pd.to_datetime(\n",
    "#    epochwavdf['Date'].str.replace('00:00:00', '') + codas['TagOnTime'], # concatenate Date and TagOnTime\n",
    "#        format='%Y-%m-%d %H:%M:%S'\n",
    "#    ) + pd.to_timedelta(codas['TsTo'], unit='seconds') # Add TsTo\n",
    "\n",
    "epochwavdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460a9cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "birthwavdf = dir2df(birthdir, fnpat='^CETI\\d+-\\d+\\.wav$', addcols=['barename', 'ext'])\n",
    "birthwavdf = birthwavdf.merge(epochwavdf, how='left', on='barename')\n",
    "birthwavdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78240a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def codadf2clickdf(codadf, codacol, t1col):\n",
    "    '''\n",
    "    Convert a wide coda dataframe in which rows represent codas and in which\n",
    "    individual clicks times are in ICI# columns to a long format in which rows\n",
    "    are the individual clicks.\n",
    "    '''\n",
    "    df = pd.wide_to_long(\n",
    "        codadf,\n",
    "        stubnames='ICI',\n",
    "        i=codacol,   # Name of column with coda id\n",
    "        j='clicknum' # Name of column in output with the ordered number of the click within each coda\n",
    "    ) \\\n",
    "    .reset_index() \\\n",
    "    .groupby(codacol).apply(\n",
    "        lambda x: x[(x['ICI'] != 0) | ~x['ICI'].duplicated()]  # Remove duplicated ICI rows == 0.0\n",
    "    ) \\\n",
    "    .reset_index(drop=True)\n",
    "    # Add annotated t1 of the click\n",
    "    df['t1'] = df.groupby(codacol, group_keys=False).apply(\n",
    "        lambda x: x['ICI'].shift(fill_value=x.iloc[0][t1col]).cumsum()\n",
    "    )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93582ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with available audio files in birthdir.\n",
    "# Only codas with matching audio files are in the result.\n",
    "birthclicks = codadf2clickdf(\n",
    "    pd.read_csv(birthcsv).reset_index().rename(columns={'index': 'fauxcoda'}),\n",
    "    codacol='fauxcoda',\n",
    "    t1col='TfS'\n",
    ").reset_index(drop=True)\n",
    "birthclicks = birthwavdf.merge(birthclicks, how='inner', left_on='barename', right_on='Recording')\n",
    "birthclicks['t1datetime'] = birthclicks['wavdatetime'] + pd.to_timedelta(birthclicks['t1'], unit='seconds')\n",
    "#badclick = clicks['TfS'] >= clicks['flacdur']\n",
    "#missingcodas = clicks[badclick]\n",
    "#clicks = clicks[~badclick].reset_index(drop=True)\n",
    "#print(f\"Removed {badclick.count()} clicks from {(missingcodas['codaNUM2018'].unique().shape[0])} codas because of bad click times (TsTo > flac file duration).\")\n",
    "birthclicks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42c59a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://docs.google.com/spreadsheets/d/16sq2PELqJC0OkRl_8w5HWouN7fYceMD0/edit?usp=sharing&ouid=117760404675948047191&rtpof=true&sd=true\n",
    "birthbhv_spreadsheet_id = '16sq2PELqJC0OkRl_8w5HWouN7fYceMD0'\n",
    "birthbhv_gid = '425969070'\n",
    "birth_bhvurl = f'https://docs.google.com/spreadsheets/d/{birthbhv_spreadsheet_id}/export?format=csv&gid={birthbhv_gid}'\n",
    "birth_bhvdf = pd.read_csv(birth_bhvurl)\n",
    "birth_bhvdf['bhvdt'] = pd.to_datetime(birth_bhvdf['UTC'], unit='ms')\n",
    "birth_bhvdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47c0627",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "birthbehavdf = pd.read_excel(birthbehavxlsx)\n",
    "birthbehavdf['eventdt'] = pd.to_datetime(birthbehavdf['Local Time including TiF'], format='%Y-%m-%d %H:%M:%S')\n",
    "birthbehavdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4c4508",
   "metadata": {},
   "source": [
    "TODO: align click and behavioral events using 'nearest' criterion. Also include distance (in time) from event to click. \n",
    "\n",
    "TODO: check interpretatioin of `Epoch Timestamp from Drone`, `Time in File`, and `Local Time including TiF` columns. Probably `Time in File` refers to time in chunked file, not time in reconstituted full-length file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687e9331",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge_asof(birthclicks.sort_values('t1datetime'), birthbehavdf.sort_values('eventdt'), left_on='t1datetime', right_on='eventdt')\n",
    "(df['t1datetime'] - df['eventdt']).describe()\n",
    "#birthclick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e552c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['t1datetime'] - df['eventdt'] < datetime.timedelta(seconds=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c4cd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "birthclicks.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4ae468",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort as desired. Add a zero-based column that can\n",
    "# be used to match rows (first dimension) of extracted audio ndarray.\n",
    "birthclicks = birthclicks.sort_values(['SegmentWhale', 'fauxcoda', 'clicknum']).reset_index(drop=True).reset_index(names='audidx')\n",
    "birthclicks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e12eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "birthaudio = ceti.extract_click_audio(\n",
    "    birthclicks, 'fauxcoda', 't1', click_offset, click_window, birthdir, birthresample_rate, 'barename'\n",
    ")\n",
    "birthaudio = ceti.normalize_audio(birthaudio, remdc=True, peak_scale=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27cab8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(birthaudio[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7237ea30",
   "metadata": {},
   "outputs": [],
   "source": [
    "birthaudio.shape, birthclicks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6cde6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally save the audio\n",
    "tstamp = get_timestamp_now()[0]\n",
    "leftout = birthdir.parent / f'birthclicks.{tstamp}.wav'\n",
    "sf.write(leftout, birthaudio[birthclicks.index].ravel(), resample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4bd0c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally save the audio\n",
    "tstamp = get_timestamp_now()[0]\n",
    "for s, saudio in (('unscaled', birthaudio), ('pknorm', ceti.normalize_audio(birthaudio.copy(), remdc=False, peak_scale=1.0))):\n",
    "    outfile = flacdir.parent / f'birthclicks.{tstamp}.{s}.{saudio.shape[-1]}samples.wav'\n",
    "    wavfile.write(outfile, birthresample_rate, saudio.ravel())\n",
    "#    sf.write(outfile, clickaudio[:,chanidx,:].ravel(), resample_rate) # This seems to scale audio\n",
    "    print(outfile)\n",
    "\n",
    "# Save click dataframe. The `audidx` column matches dataframe rows to\n",
    "# its sequence in the audio file.\n",
    "csvout = flacdir.parent / f'birthclicks.{tstamp}.csv'\n",
    "birthclicks.to_csv(csvout, index=False)\n",
    "print(csvout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e09a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "birthclicks = birthclicks.reset_index(drop=True)\n",
    "whaledf = pd.DataFrame({\n",
    "    'text': birthclicks[~birthclicks['SegmentWhale'].duplicated()]['SegmentWhale'].astype(str),\n",
    "    't1': birthclicks[~birthclicks['SegmentWhale'].duplicated()].index * click_window,\n",
    "    't2': birthclicks[~birthclicks['SegmentWhale'].duplicated(keep='last')].index * click_window + click_window\n",
    "})\n",
    "whaledf\n",
    "\n",
    "codadf = pd.DataFrame({\n",
    "    'text': birthclicks[~birthclicks['fauxcoda'].duplicated()]['fauxcoda'].astype(str),\n",
    "    't1': birthclicks[~birthclicks['fauxcoda'].duplicated()].index * click_window,\n",
    "    't2': birthclicks[~birthclicks['fauxcoda'].duplicated(keep='last')].index * click_window + click_window\n",
    "})\n",
    "codadf\n",
    "\n",
    "clickdf = pd.DataFrame({\n",
    "    'text': birthclicks['clicknum'].astype(str),\n",
    "    't1': birthclicks.index * click_window,\n",
    "    't2': birthclicks.index * click_window + click_window\n",
    "})\n",
    "clickdf\n",
    "\n",
    "clicktg = df2tg(\n",
    "    [whaledf, codadf, clickdf],\n",
    "    tnames=['whale', 'coda', 'clicknum'],\n",
    "    lbl='text',\n",
    "    fmt='0.4f',\n",
    "    fill_gaps=None,\n",
    "    outfile=specdir.parent / f'birthclicks.{tstamp}.TextGrid'\n",
    ")\n",
    "print(outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ebcb7e",
   "metadata": {},
   "source": [
    "# Leftovers\n",
    "\n",
    "Code not currently in use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738d4b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# Use parselmouth to get ltas from praat\n",
    "# Assemble all audio as a single concatenated .wav file\n",
    "# For metadata csv file, just grab the whole row from classifiedCodasProc and add to click csv\n",
    "# Append spectral data to metadata .csv file (long format as binHz & binAmp columns)\n",
    "# Also assemble audio slices as ndarray and save in R-compatible format\n",
    "\n",
    "# TODO\n",
    "# pad 25ms\n",
    "# resample 48k\n",
    "# play with spectral analysis and formants\n",
    "\n",
    "def hhmmss2sec(s):\n",
    "    '''\n",
    "    Convert a HH:MM:SS string to seconds.\n",
    "    '''\n",
    "    hh, mm, ss = s.split(':')\n",
    "    return int(hh) * 3600 + int(mm) * 60 + int(ss)\n",
    "\n",
    "def praat_ltas(snd, bwhz, return_freqs):\n",
    "    ltas = pcall(snd, 'To Ltas...', bwhz)\n",
    "    nbins = pcall(ltas, 'Get number of bins')\n",
    "    vals = [pcall(ltas, 'Get value in bin', i) for i in range(1, nbins+1)]\n",
    "    if return_freqs is True:\n",
    "        freqs = [\n",
    "            pcall(ltas, 'Get frequency from bin number...', i) for i in range(1, nbins+1)\n",
    "        ]\n",
    "        return (vals, freqs)\n",
    "    else:\n",
    "        return vals\n",
    "\n",
    "def load_flac_info(flacdir):\n",
    "    '''\n",
    "    Find all .flac files and load as a dataframe with samplerate and durations.\n",
    "    \n",
    "    If cached results are available, use those instead.\n",
    "    '''\n",
    "    flacinfofile = flacdir / 'flacinfo.csv'\n",
    "    if flacinfofile.exists():\n",
    "        dtypes = {\n",
    "            'relpath': str,\n",
    "            'fname': str,\n",
    "            'barename': str,\n",
    "            'flacrate': int,\n",
    "            'flacdur': float,\n",
    "            'tag': str,\n",
    "            'fseq': int,\n",
    "            'foffset': float\n",
    "        }\n",
    "        flacdf = pd.read_csv(flacinfofile, dtype=dtypes)\n",
    "    else:\n",
    "        flacdf = dir2df(flacdir, fnpat='(?P<tag>[a-z]+\\d+[a-z])(?P<fseq>\\d+)\\.flac$', dirpat=r'20\\d\\d', addcols=['barename', 'ext'])\n",
    "        flacdf['fseq'] = flacdf['fseq'].astype(int)\n",
    "        flacdf['flacrate'] = [sf.info(flacdir / f.relpath / f.fname).samplerate for f in flacdf.itertuples()]\n",
    "        flacdf['flacdur'] = [sf.info(flacdir / f.relpath / f.fname).duration for f in flacdf.itertuples()]\n",
    "        flacdf['foffset'] = flacdf.groupby('tag', group_keys=False).apply(\n",
    "            lambda x: x['flacdur'].shift(fill_value=0).cumsum()\n",
    "        )\n",
    "        flacdf.to_csv(flacinfofile, index=False)\n",
    "    return flacdf\n",
    "\n",
    "def load_classified_codas(url, dropIPI):\n",
    "    '''\n",
    "    Load codas found in google classifiedCodasProc spreadsheet as a dataframe.\n",
    "    '''\n",
    "    codas = pd.read_csv(\n",
    "        url, dtype={'codaNUM2018': str, 'IDN': str, 'nClicks': np.int64}\n",
    "    )\n",
    "    if dropIPI is True:   # Drop IPI# columns if requested\n",
    "        codas = codas.drop(\n",
    "            [c for c in codas.columns if c.startswith('IPI')],\n",
    "            axis='columns'\n",
    "        )\n",
    "    barenamere = re.compile(r'''\n",
    "        (?P<barename>             # Corresponds to .flac filename\n",
    "          (?P<tagmatch>sw\\d+[a-z]) # Expected to match 'Tag' column\n",
    "          (?P<fileseq>\\d+)        # Sequence of this file in audio files for Tag\n",
    "        )\n",
    "        (?:\n",
    "          _                     # Separator for optional\n",
    "          (?P<seg>.+)           # following digits of unknown meaning\n",
    "        )?\n",
    "    ''', re.VERBOSE)\n",
    "    codas = pd.concat(\n",
    "        [\n",
    "            codas['REC'].str.extract(barenamere).fillna(''),\n",
    "            codas\n",
    "        ],\n",
    "        axis='columns'\n",
    "    )\n",
    "    assert((codas['tagmatch'] == codas['Tag']).all())\n",
    "    return codas.drop('tagmatch', axis='columns')\n",
    "\n",
    "def load_cached_spectra(csvfile):\n",
    "    '''\n",
    "    Load spectral analysis from cached .npy and .csv files.\n",
    "    '''\n",
    "    return {\n",
    "        'wfreqs': np.load(csvfile.with_suffix('.welchfreqs.npy')),\n",
    "        'pfreqs': np.load(csvfile.with_suffix('.praatfreqs.npy')),\n",
    "        'lfreqs': np.load(csvfile.with_suffix('.ltasfreqs.npy')),\n",
    "        'au': np.load(csvfile.with_suffix('.audio.npy')),\n",
    "        'welch': np.load(csvfile.with_suffix('.welchspec.npy')),\n",
    "        'praat': np.load(csvfile.with_suffix('.praatspec.npy')),\n",
    "        'ltas': np.load(csvfile.with_suffix('.ltasspec.npy')),\n",
    "        'md': pd.read_csv(\n",
    "            csvfile,\n",
    "            dtype={'codaNUM2018': str, 'clicknum': int, 'text': str, 'IDN': str}\n",
    "        )\n",
    "    }\n",
    "\n",
    "def get_single_click_audio(aufile, t1, click_offset, click_window, resample_rate, verbose=True):\n",
    "    with sf.SoundFile(aufile, 'r') as fh:\n",
    "        sr_native = fh.samplerate\n",
    "        nsamp = int(click_window * sr_native)\n",
    "        fh.seek(int((t1 + click_offset) * sr_native))\n",
    "        # Load the target number of frames, and transpose to match librosa form\n",
    "        y = fh.read(frames=nsamp, dtype=np.float32, always_2d=False).T\n",
    "        if sr_native != resample_rate:\n",
    "            y = librosa.resample(y, orig_sr=sr_native, target_sr=resample_rate)\n",
    "        if verbose is True:\n",
    "            print(f'Read from time {t1 + click_offset} in {aufile}')\n",
    "    return y\n",
    "\n",
    "def extract_click_audio(clickdf, codacol, t1col, click_offset, click_window, audiodir, resample_rate, groupby):\n",
    "    '''\n",
    "    Extract audio chunks for each click row in a dataframe.\n",
    "    \n",
    "    For better performance the input dataframe is sorted by source file and coda id.\n",
    "    '''\n",
    "    try:\n",
    "        assert(clickdf.index.start == 0)\n",
    "        assert(clickdf.index.step == 1)\n",
    "    except AssertionError:\n",
    "        raise RuntimeError('Input dataframe must have a zero-based range index.')\n",
    "    audio = None\n",
    "#    audio2 = None\n",
    "#    dfs = []\n",
    "    errors = []\n",
    "#    clickdf = clickdf.copy() \\\n",
    "#                     .sort_values(['barename', codacol]) \\\n",
    "#                     .reset_index(drop=True)\n",
    "#    idx = 0\n",
    "    for _, audf in clickdf.groupby(groupby):\n",
    "        aufile = Path(audiodir) / audf.iloc[0]['relpath'] / f\"{audf.iloc[0][groupby]}{audf.iloc[0]['ext']}\"\n",
    "        with sf.SoundFile(aufile, 'r') as fh:\n",
    "            sr_native = fh.samplerate\n",
    "            if sr_native < resample_rate:\n",
    "                sys.stderr.write(\n",
    "                    f'WARNING: Upsampling {aufile} from {sr_native} to {resample_rate}.\\n'\n",
    "                )\n",
    "            nsamp = int(click_window * sr_native)\n",
    "            for __, cdf in audf.groupby(codacol):\n",
    "                for row in cdf.itertuples():\n",
    "                    try:\n",
    "                        fh.seek(int((row.t1 + click_offset) * sr_native))\n",
    "                        # Load the target number of frames, and transpose to match librosa form\n",
    "                        y = fh.read(frames=nsamp, dtype=np.float32, always_2d=False).T\n",
    "                        if sr_native != resample_rate:\n",
    "                            y = librosa.resample(\n",
    "                                y, orig_sr=sr_native, target_sr=resample_rate\n",
    "                            )\n",
    "                        if audio is None:\n",
    "                            audio = (\n",
    "                                np.empty(\n",
    "                                    (len(clickdf), ) + y.shape,\n",
    "                                    dtype=np.float32\n",
    "                                ) * np.nan\n",
    "                            )\n",
    "#                            audio2 = (\n",
    "#                                np.empty(\n",
    "#                                    (len(clickdf), ) + y.shape,\n",
    "#                                    dtype=np.float32\n",
    "#                                ) * np.nan\n",
    "#                            )\n",
    "                    except Exception as e:\n",
    "                        errors.append(row.Index)\n",
    "                    audio[row.audidx] = y\n",
    "#                    audio[row.Index] = y\n",
    "#                    audio2[row.audidx] = y\n",
    "    audio = np.array(audio)\n",
    "#    audio2 = np.array(audio2)\n",
    "    mu = audio.mean(axis=-1, keepdims=True)\n",
    "#    mu2 = audio2.mean(axis=-1, keepdims=True)\n",
    "    audio -= mu # Remove DC offset\n",
    "#    audio2 -= mu2 # Remove DC offset\n",
    "    audio /= np.abs(audio).max(axis=-1, keepdims=True) * 0.99  # Normalize max magnitude to 0.99\n",
    "#    audio2 /= np.abs(audio2).max(axis=-1, keepdims=True) * 0.99  # Normalize max magnitude to 0.99\n",
    "    return (audio, clickdf[clickdf.index.isin(errors)])\n",
    "\n",
    "# TODO: as-is this is too particular for a specific dataframe\n",
    "def clicks2tg(mydf):\n",
    "    '''\n",
    "    Compile textgrid tiers from dataframe of clicks.\n",
    "    '''\n",
    "    clickdf = pd.DataFrame({\n",
    "        'whale': mydf['Name'],\n",
    "        'coda': mydf['codaNUM2018'],\n",
    "        'click': mydf['clicknum'].astype(str),\n",
    "        't1': mydf.index * click_window,\n",
    "        't2': (mydf.index + 1) * click_window\n",
    "    })\n",
    "    clickdf = clickdf.set_index(['whale', 'coda'])\n",
    "\n",
    "    whaledf = clickdf[['t1', 't2']] \\\n",
    "              .groupby('whale') \\\n",
    "              .agg([min, max]) \\\n",
    "              .loc[:, [('t1', 'min'), ('t2', 'max')]] \\\n",
    "              .droplevel(1, axis='columns') \\\n",
    "              .reset_index()\n",
    "\n",
    "    codadf = clickdf[['t1', 't2']] \\\n",
    "              .groupby(['coda']) \\\n",
    "              .agg([min, max]) \\\n",
    "              .loc[:, [('t1', 'min'), ('t2', 'max')]] \\\n",
    "              .droplevel(1, axis='columns') \\\n",
    "              .reset_index()\n",
    "\n",
    "    clicktg = df2tg(\n",
    "        [whaledf, codadf, clickdf],\n",
    "        tnames=['whale', 'coda-bout', 'clicknum'],\n",
    "        lbl=['whale', 'coda', 'click'],\n",
    "        fmt='0.4f',\n",
    "        outfile=specdir.parent / 'allcodas-clicks.focal.20231005.2.fg.TextGrid'\n",
    "    )\n",
    "\n",
    "def codas2clicks(codadf):\n",
    "    '''\n",
    "    Transform the codas in a dataframe to a list of per-whale\n",
    "    coda|click dataframes and associated names of the form\n",
    "    `{whaleid}-(codas|clicks)`.\n",
    "    '''\n",
    "    codalists = {}\n",
    "    for coda in codadf.itertuples():\n",
    "        codadict = {\n",
    "            't1': coda.TsTo,\n",
    "            't2': coda.TsTo + coda.Duration,\n",
    "        }\n",
    "        try:\n",
    "            codalists[f'{coda.IDN}-codas'].append(coda._asdict() | codadict)\n",
    "        except KeyError:\n",
    "            codalists[f'{coda.IDN}-codas'] = [coda._asdict() | codadict]\n",
    "        t1 = coda.TsTo\n",
    "        for clicknum in np.arange(1, coda.nClicks + 1, dtype=int):\n",
    "            clickdur = getattr(coda, f'ICI{int(clicknum)}')\n",
    "            clickdict = {\n",
    "                't1': t1,\n",
    "                'clicknum': clicknum,\n",
    "            }\n",
    "            try:\n",
    "                codalists[f'{coda.IDN}-clicks'].append(coda._asdict() | clickdict)\n",
    "            except KeyError:\n",
    "                codalists[f'{coda.IDN}-clicks'] = [coda._asdict() | clickdict]\n",
    "            t1 += clickdur\n",
    "    dfs = []\n",
    "    for v in codalists.values():\n",
    "        vdf = pd.DataFrame(v)\n",
    "        vdf['nClicks'] = vdf['nClicks'].astype(str)\n",
    "        if 'clicknum' in vdf.columns:\n",
    "            vdf['clicknum'] = vdf['clicknum'].astype(str)\n",
    "        dfs.append(vdf.drop('Index', axis='columns'))\n",
    "    return (dfs, list(codalists.keys()))\n",
    "\n",
    "def specs2long(row, welchspecarray, praatspecarray, ltasspecarray, freqs):\n",
    "    '''\n",
    "    Arrange spectral measures in long format and combine with click metadata\n",
    "    keys for later merging.\n",
    "    '''\n",
    "    return {\n",
    "        'codaNUM2018': row.codaNUM2018,\n",
    "        'clicknum': row.clicknum,\n",
    "        'binHz': np.hstack((freqs['welch'], freqs['praat'], freqs['ltas'])),\n",
    "        'binval': np.hstack((\n",
    "            (10*np.log10(np.abs(welchspecarray[row.Index])/2e-5)),\n",
    "            (10*np.log10(np.abs(praatspecarray[row.Index,0,:])/2e-5)),\n",
    "            ltasspecarray[row.Index]\n",
    "        )),\n",
    "        'spectype': \\\n",
    "            ['welch'] * len(freqs['welch']) + \\\n",
    "            ['praat'] * len(freqs['praat']) + \\\n",
    "            ['ltas'] * len(freqs['ltas'])\n",
    "    }\n",
    "\n",
    "def get_click_audio_old(fh, t1s, rate, offset, window, mono):\n",
    "    '''\n",
    "    Get all the audio corresponding to rows of a dataframe. All rows are\n",
    "    expected to have the same 'relpath' and 'fname' values for the .flac file.\n",
    "    '''\n",
    "    audio = []\n",
    "    t1s = clickdf['ICI'].shift(fill_value=clickdf.iloc[0]['TsTo']).cumsum()\n",
    "    for t1 in t1s:\n",
    "        au, _ = librosa.load(\n",
    "            fh, sr=rate, mono=mono, offset=t1+offset, duration=window\n",
    "        )\n",
    "        audio.append(au)\n",
    "    return audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f91482",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -r1 -n1\n",
    "audio = []\n",
    "for _, flacdf in allcodas.groupby('barename'):\n",
    "    flacfile = flacdir / flacdf.iloc[0]['relpath'] / flacdf.iloc[0]['fname']\n",
    "    with sf.SoundFile(flacfile, 'r') as fh:\n",
    "        sr_native = fh.samplerate\n",
    "        if sr_native < resample_rate:\n",
    "            sys.stderr.write(f'WARNING: Upsampling {flacfile} from {sr_native} to {resample_rate}.\\n')\n",
    "        nsamp = int(click_window * sr_native)\n",
    "        for __, clickdf in flacdf.groupby('codaNUM2018'):\n",
    "            t1s = clickdf['ICI'].shift(fill_value=clickdf.iloc[0]['TsTo']).cumsum()\n",
    "            for t1 in t1s:\n",
    "                fh.seek(int((t1 + click_offset) * sr_native))\n",
    "                # Load the target number of frames, and transpose to match librosa form\n",
    "                y = fh.read(frames=nsamp, dtype=np.float32, always_2d=False).T\n",
    "                audio.append(\n",
    "                    librosa.resample(y, orig_sr=sr_native, target_sr=resample_rate)\n",
    "                )\n",
    "audio = np.array(audio)\n",
    "mu = audio.mean(axis=-1, keepdims=True)\n",
    "audio -= mu # Remove DC offset\n",
    "audio /= np.abs(audio).max(axis=-1, keepdims=True) * 0.99  # Normalize max magnitude to 0.99"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6811e0",
   "metadata": {},
   "source": [
    "## Process codas\n",
    "\n",
    "Find all coda entries that have a matching `.flac` file and do spectral analysis on the clicks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503ab269",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "results = {'success': [], 'failure': []}\n",
    "mycodas = allcodas[(allcodas['relpath'] != '') & (allcodas['REC'] != '')]\n",
    "for name, codadf in mycodas.groupby('barename'):\n",
    "    # Create per-whale coda and click dataframes for a .flac file.\n",
    "    dfs, tiers = codas2clicks(codadf)\n",
    "\n",
    "    # Write the results to a textgrid.\n",
    "    relpath = codadf.iloc[0]['relpath']\n",
    "    tgfile = tgdir / relpath / f'{name}.tg'\n",
    "    tgfile.parent.mkdir(parents=True, exist_ok=True)\n",
    "    tg = df2tg(\n",
    "        dfs,\n",
    "        tnames=tiers,\n",
    "        t2=['t2' if 't2' in df.columns else None for df in dfs],\n",
    "        lbl=['clicknum' if 'clicknum' in df.columns else 'nClicks' for df in dfs],\n",
    "        fmt='0.4f',\n",
    "        fill_gaps=None,  # Some codas overlap, which makes textgrid unreadable by Praat if this is True\n",
    "        outfile=tgfile\n",
    "    )\n",
    "\n",
    "    # Get spectra of individual clicks in a .flac file.\n",
    "    for tname, df in zip(tiers, dfs):\n",
    "        # Process -clicks dfs and skip -codas dfs.\n",
    "        if not tname.endswith('-clicks'):\n",
    "            continue\n",
    "        wspectra = []\n",
    "        ltasspectra = []\n",
    "        praatspectra = []\n",
    "        audio = []\n",
    "        freqs = {}\n",
    "        skiperror = False\n",
    "        for row in df.itertuples():\n",
    "            flacfile = flacdir / relpath / f'{name}.flac'\n",
    "            try:\n",
    "#                print(click)\n",
    "                au, _ = librosa.load(\n",
    "                    flacfile,\n",
    "                    sr=resample_rate,\n",
    "                    offset=row.t1+click_offset,\n",
    "                    duration=click_window\n",
    "                )\n",
    "                au = au - au.mean()  # Remove DC offset\n",
    "                au = au / np.abs(au).max() * 0.99  # Normalize max magnitude to 0.99\n",
    "                welchfreqs, Pxx = welch(au, fs=resample_rate, nperseg=1024)\n",
    "                snd = Sound(values=au, sampling_frequency=resample_rate)\n",
    "                praatspec = snd.to_spectrum(fast=praat_spec_fast)\n",
    "                if freqs == {}:\n",
    "                    ltas, ltasfreqs = praat_ltas(snd, ltas_bw, True)\n",
    "                    freqs = {\n",
    "                        'welch': welchfreqs,\n",
    "                        'ltas': ltasfreqs,\n",
    "                        'praat': praatspec.xs()\n",
    "                    }\n",
    "                else:\n",
    "                    ltas = praat_ltas(snd, ltas_bw, False)\n",
    "                wspectra.append(Pxx)\n",
    "                ltasspectra.append(ltas)\n",
    "                praatspectra.append(praatspec)\n",
    "                audio.append(au)\n",
    "                results['success'].append(f'{row.codaNUM2018}-{row.clicknum}')\n",
    "            except Exception as e:\n",
    "                results['failure'].append(f'{row.codaNUM2018}-{row.clicknum}')\n",
    "                if skiperror is False:\n",
    "                    sys.stderr.write(f'Could not process \"{flacfile}\" at time {row.t1}: {e}\\n\\n')\n",
    "                    skiperror = True\n",
    "        # Save results\n",
    "        csvfile = specdir / relpath / f\"{name}.{df.iloc[0]['IDN']}.csv\"\n",
    "        csvfile.parent.mkdir(parents=True, exist_ok=True)\n",
    "        df.to_csv(csvfile, index=False)\n",
    "        np.save(csvfile.with_suffix('.welchspec.npy'), np.array(wspectra))\n",
    "        np.save(csvfile.with_suffix('.praatspec.npy'), np.array(praatspectra))\n",
    "        np.save(csvfile.with_suffix('.ltasspec.npy'), np.array(ltasspectra))\n",
    "        np.save(csvfile.with_suffix('.audio.npy'), np.array(audio))\n",
    "        print(f'Finished {flacfile}')\n",
    "        if freqs != {}:\n",
    "            np.save(csvfile.with_suffix('.welchfreqs.npy'), freqs['welch'])\n",
    "            np.save(csvfile.with_suffix('.praatfreqs.npy'), freqs['praat'])\n",
    "            np.save(csvfile.with_suffix('.ltasfreqs.npy'), freqs['ltas'])\n",
    "#            break\n",
    "#        break\n",
    "#    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedf1895",
   "metadata": {},
   "outputs": [],
   "source": [
    "stdfs = []\n",
    "for status in ('success', 'failure'):\n",
    "    stdf = pd.DataFrame({\n",
    "        'status': status,\n",
    "        'codanum': [r.split('-')[0] for r in results[status]]\n",
    "    })\n",
    "    stdfs.append(stdf[~stdf.duplicated()].reset_index(drop=True))\n",
    "statusdf = pd.concat(stdfs, axis='rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abed572",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "resultsdf = statusdf.merge(allcodas, how='outer', left_on='codanum', right_on='codaNUM2018')\n",
    "Is = [c for c in resultsdf.columns if c.startswith('ICI') or c.startswith('IPI')]\n",
    "resultsdf = resultsdf.drop(Is, axis='columns')\n",
    "#resultsdf['TagOnSec'] = resultsdf['TagOnTime'].str.split(':', expand=True).fillna('0').astype(int).apply(lambda x: x[0] * 3600 + x[1] * 60 + x[2], axis='columns')\n",
    "resultsdf[['status', 'barename', 'TagOnTime', 'TsTo', 'SampleRate', 'flacrate']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21fc843",
   "metadata": {},
   "source": [
    "## Load results of last file/whale analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd251ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "spectra = load_cached_spectra(csvfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b42915a",
   "metadata": {},
   "outputs": [],
   "source": [
    "spectra['wfreqs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c074595",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = 1\n",
    "fig, axs = plt.subplots(6, 1, figsize=[10, 40])\n",
    "axs[0].plot(myaudio[frame])\n",
    "axs[0].set_title = 'audio'\n",
    "axs[1].plot(mywelchfreqs, mywelchspecs[frame,:])\n",
    "axs[1].set_title = 'welch spectrum'\n",
    "axs[2].plot(mywelchfreqs, 10*np.log10(mywelchspecs[frame,:]/2e-5))\n",
    "axs[2].set_title = 'log-scaled welch spectrum'\n",
    "axs[2].set_ylim(-100, 0)\n",
    "axs[3].plot(mypraatfreqs, np.abs(mypraatspecs[frame,0,:]))\n",
    "axs[3].set_title = 'praat spectrum'\n",
    "axs[4].plot(mypraatfreqs, 10*np.log10(np.abs(mypraatspecs[frame,0,:])/2e-5))\n",
    "axs[4].set_title = 'log-scaled praat spectrum'\n",
    "#axs[4].set_ylim(-100, 0)\n",
    "axs[5].plot(myltasfreqs, np.abs(myltasspecs[frame,:]))\n",
    "axs[5].set_title = 'praat ltas spectrum'\n",
    "fig.tight_layout()\n",
    "print(mydf.iloc[frame])\n",
    "audio = Audio(data=myaudio[frame], rate=resample_rate)\n",
    "display(audio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7b36e4",
   "metadata": {},
   "source": [
    "## Assemble all spec and csv files\n",
    "\n",
    "These contain corresponding rows of spectral data and metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67bdd546",
   "metadata": {},
   "outputs": [],
   "source": [
    "welchspecdf = dir2df(specdir, fnpat=r'(?P<flacfile>[^.]+)\\.(?P<whaleid>[^.]+)\\.welchspec.npy')\n",
    "praatspecdf = dir2df(specdir, fnpat=r'(?P<flacfile>[^.]+)\\.(?P<whaleid>[^.]+)\\.praatspec.npy')\n",
    "ltasspecdf = dir2df(specdir, fnpat=r'(?P<flacfile>[^.]+)\\.(?P<whaleid>[^.]+)\\.ltasspec.npy')\n",
    "csvdf = dir2df(specdir, fnpat=r'(?P<flacfile>[^.]+)\\.(?P<whaleid>[^.]+)\\.csv')\n",
    "welchspeccsvdf = welchspecdf.merge(csvdf, how='inner', on=('relpath', 'flacfile', 'whaleid'), suffixes=('_spec', '_csv'))\n",
    "welchspeccsvdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a38ec5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# x Normalize audio peaks to .99\n",
    "# x Order clicks by whale before saving audio/creating spectra\n",
    "# Compare AWS audio files to GDrive files to see whether they are not truncated\n",
    "# x Textgrid for all audio file that shows 1) tier 1 with whalename_bout 2) tier 2 coda 3) tier 3 clicknum\n",
    "# Save metadata/spectral results in wide and long formats, separated by analysis type\n",
    "# x Remove log scaling from values\n",
    "# Save as rda file?\n",
    "welchspecs = []\n",
    "praatspecs = []\n",
    "ltasspecs = []\n",
    "csvs = []\n",
    "auds = []\n",
    "freqs = {}\n",
    "allspecs = []\n",
    "for row in welchspeccsvdf.itertuples():\n",
    "    csvfile = specdir / row.relpath / row.fname_csv\n",
    "    try:\n",
    "        spectra = load_cached_spectra(csvfile)\n",
    "        md, au = spectra['md'], spectra['au']\n",
    "        assert(len(md) == len(au))\n",
    "        ws, ps, ls = spectra['welch'], spectra['praat'], spectra['ltas']\n",
    "        welchspecs.append(ws)\n",
    "        praatspecs.append(ps)\n",
    "        ltasspecs.append(ls)\n",
    "        csvs.append(md)\n",
    "        auds.append(au)\n",
    "        freqs = {\n",
    "            'welch': spectra['wfreqs'],\n",
    "            'praat': spectra['pfreqs'],\n",
    "            'ltas': spectra['lfreqs']\n",
    "        }\n",
    "        allspecs.append(pd.DataFrame({\n",
    "            'binHz': np.hstack((freqs['welch'], freqs['praat'], freqs['ltas'])),\n",
    "            'binval': np.hstack([\n",
    "                ws[idx], #                (10*np.log10(np.abs(ws[idx])/2e-5)),\n",
    "                ps[idx,0,:], #                (10*np.log10(np.abs(ps[idx,0,:])/2e-5)),\n",
    "                ls[idx]\n",
    "            ]),\n",
    "            'spectype': \\\n",
    "                ['welch'] * len(freqs['welch']) + \\\n",
    "                ['praat'] * len(freqs['praat']) + \\\n",
    "                ['ltas'] * len(freqs['ltas'])\n",
    "        }))\n",
    "    except AssertionError as e:\n",
    "        print(f'md {md.shape} and au {au.shape} for {csvfile} do not match.\\n')\n",
    "    except Exception as e:\n",
    "#        print(f'Could not load md and spectra for {csvfile}:\\n{e}')\n",
    "        continue\n",
    "# Reset index to ensure zero-based indexing to coordinate with np arrays.\n",
    "csvdf = pd.concat(csvs, axis='rows').reset_index(drop=True)\n",
    "### Sort by whale, coda, click\n",
    "csvdf = csvdf.sort_values(['Name', 'codaNUM2018', 'clicknum'])\n",
    "\n",
    "# Use csvdf.Index to assure same sort as csvdf\n",
    "welchspecarray = np.vstack(welchspecs)[csvdf.index]\n",
    "praatspecarray = np.vstack(praatspecs)[csvdf.index]\n",
    "ltasspecarray = np.vstack(ltasspecs)[csvdf.index]\n",
    "audioarray = np.vstack(auds)[csvdf.index]\n",
    "\n",
    "# Now reset index to zero-based to match np arrays\n",
    "csvdf = csvdf.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b79a6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for focal whales only\n",
    "# Optional step (execute only once!)\n",
    "focalidx = csvdf[csvdf['Focal'] == 1].index\n",
    "csvdf = csvdf.loc[focalidx,:]\n",
    "welchspecarray = welchspecarray[focalidx]\n",
    "praatspecarray = praatspecarray[focalidx]\n",
    "ltasspecarray = ltasspecarray[focalidx]\n",
    "audioarray = audioarray[focalidx]\n",
    "csvdf = csvdf.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270a22af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally save the audio\n",
    "wavout = specdir.parent / 'allcodas.focal.20231004.wav'\n",
    "sf.write(wavout, audioarray.ravel(), resample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be9ef58",
   "metadata": {},
   "outputs": [],
   "source": [
    "csvdf.shape, audioarray.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a4fa5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "welchspecarray.shape, praatspecarray.shape, ltasspecarray.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1e5fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs['welch'].shape, freqs['praat'].shape, freqs['ltas'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3495c756",
   "metadata": {},
   "outputs": [],
   "source": [
    "longspecs = [\n",
    "    specs2long(\n",
    "        r, welchspecarray, praatspecarray, ltasspecarray, freqs\n",
    "    ) for r in csvdf.itertuples()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46aae29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "longspecsdf = pd.concat([pd.DataFrame(d) for d in longspecs])\n",
    "longspecsdf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd860ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "finaldf = longspecsdf.merge(csvdf, how='left', on=('codaNUM2018', 'clicknum'))\n",
    "finaldf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580c5d8f",
   "metadata": {},
   "source": [
    "### Make textgrid tiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3186de",
   "metadata": {},
   "outputs": [],
   "source": [
    "finwelchdf = finaldf[\n",
    "    (finaldf['spectype'] == 'welch') & \\\n",
    "    (finaldf['binHz'] == 0.0)\n",
    "].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951691ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "finwelchdf.shape[0] * click_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb68234",
   "metadata": {},
   "outputs": [],
   "source": [
    "finaldf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea06a37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Whale tier\n",
    "whales = []\n",
    "codas = []\n",
    "clicks = []\n",
    "for wgb in finwelchdf.groupby('Name'):\n",
    "    wht1 = (wgb[1].index[0] * click_window)\n",
    "    whales.append({\n",
    "        'text': wgb[0],\n",
    "        't1': wht1,\n",
    "        't2': wgb[1].shape[0] * click_window + wht1\n",
    "    })\n",
    "    for coda in wgb[1].reset_index().groupby('codaNUM2018'):\n",
    "        cdt1 = coda[1].index[0] * click_window + wht1\n",
    "        codas.append({\n",
    "            'text': f\"{coda[0]}-{int(coda[1].iloc[0]['Bout'])}\",\n",
    "            't1': cdt1,\n",
    "            't2': coda[1].shape[0] * click_window + cdt1\n",
    "        })\n",
    "        for row in coda[1].itertuples():\n",
    "            clt1 = row.clicknum * click_window + cdt1\n",
    "            clicks.append({\n",
    "                'text': str(row.clicknum),\n",
    "                't1': clt1,\n",
    "                't2': click_window + clt1\n",
    "            })\n",
    "whaledf = pd.DataFrame(whales)\n",
    "whaledf\n",
    "codadf = pd.DataFrame(codas)\n",
    "codadf\n",
    "clickdf = pd.DataFrame(clicks)\n",
    "clickdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b075f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "clicktg = df2tg(\n",
    "    [whaledf, codadf, clickdf],\n",
    "    tnames=['whale', 'coda-bout', 'clicknum'],\n",
    "    lbl='text',\n",
    "    fmt='0.4f',\n",
    "    fill_gaps=None,\n",
    "    outfile=specdir.parent / 'allcodas-clicks.focal.20231004.TextGrid'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b482d338",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sptyp in ('welch', 'praat', 'ltas'):\n",
    "    finalcsv = specdir / r'finalspecs.{styp}.csv'\n",
    "    finaldf[finaldf['spectype'] == styp].to_csv(finalcsv, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375e2b62",
   "metadata": {},
   "source": [
    "# Slower but less memory required\n",
    "finalcsv = specdir / 'finalspecs.csv'\n",
    "with open(finalcsv, 'a') as out:\n",
    "    for i, r in enumerate(csvdf.itertuples()):\n",
    "        finaldf = pd.DataFrame(\n",
    "            specs2long(\n",
    "                r, welchspecarray, praatspecarray, ltasspecarray, freqs\n",
    "            )\n",
    "        ) \\\n",
    "        .merge(csvdf, how='left', on=('codaNUM2018', 'clicknum')) \\\n",
    "        .to_csv(out, mode='a', index=False, header=(i==0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22543f6",
   "metadata": {},
   "source": [
    "## Read `.csv` of spectral measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854bd05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "speccsv = specdir / 'finalspecs.fast.csv'\n",
    "sdf = pd.read_csv(speccsv, nrows=100000)\n",
    "sdf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c1dc63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of codas\n",
    "sdf['codaNUM2018'].unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8113dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of coda clicks\n",
    "sgby = sdf.groupby(['codaNUM2018', 'clicknum'])\n",
    "sgby.ngroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24220179",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf.codaNUM2018.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253acae4",
   "metadata": {},
   "source": [
    "### Plot click spectrums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021c6b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "codanum = 8365\n",
    "clicknum = 3\n",
    "spectypes = ['welch', 'praat', 'ltas']\n",
    "cdf = sdf[(sdf['codaNUM2018'] == codanum) & (sdf['clicknum'] == clicknum)]\n",
    "fig, axs = plt.subplots(len(spectypes))\n",
    "for i, styp in enumerate(spectypes):\n",
    "    pltdf = cdf[cdf['spectype'] == styp]\n",
    "    axs[i].plot(pltdf['binHz'][1:], pltdf['binval'][1:])\n",
    "#axs[2].set_ylim(-25, 35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccefbf47",
   "metadata": {},
   "outputs": [],
   "source": [
    "cdf.pivot_table(index=['spectype'], columns='binHz', values='binval')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96faf45",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(6, 1, figsize=[10, 40])\n",
    "#axs[0].plot(myaudio[frame])\n",
    "#axs[0].set_title = 'audio'\n",
    "axs[1].plot(mywelchfreqs, mywelchspecs[frame,:])\n",
    "axs[1].set_title = 'welch spectrum'\n",
    "axs[2].plot(mywelchfreqs, 10*np.log10(mywelchspecs[frame,:]/2e-5))\n",
    "axs[2].set_title = 'log-scaled welch spectrum'\n",
    "axs[2].set_ylim(-100, 0)\n",
    "axs[3].plot(mypraatfreqs, np.abs(mypraatspecs[frame,0,:]))\n",
    "axs[3].set_title = 'praat spectrum'\n",
    "axs[4].plot(mypraatfreqs, 10*np.log10(np.abs(mypraatspecs[frame,0,:])/2e-5))\n",
    "axs[4].set_title = 'log-scaled praat spectrum'\n",
    "#axs[4].set_ylim(-100, 0)\n",
    "axs[5].plot(myltasfreqs, np.abs(myltasspecs[frame,:]))\n",
    "axs[5].set_title = 'praat ltas spectrum'\n",
    "fig.tight_layout()\n",
    "print(mydf.iloc[frame])\n",
    "audio = Audio(data=myaudio[frame], rate=resample_rate)\n",
    "display(audio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75a45d6",
   "metadata": {},
   "source": [
    "## Leftovers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8976a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "welchspecs = []\n",
    "praatspecs = []\n",
    "ltasspecs = []\n",
    "csvs = []\n",
    "auds = []\n",
    "freqs = {}\n",
    "for row in welchspeccsvdf.itertuples():\n",
    "    wspec = np.load(specdir / row.relpath / row.fname_spec)\n",
    "    pspec = np.load(specdir / row.relpath / row.fname_spec.replace('welch', 'praat'))\n",
    "    lspec = np.load(specdir / row.relpath / row.fname_spec.replace('welch', 'ltas'))\n",
    "    df = pd.read_csv(\n",
    "        specdir / row.relpath / row.fname_csv,\n",
    "        dtype={'codaNUM2018': str, 'clicknum': int, 'text': str, 'IDN': str}\n",
    "    )\n",
    "    aud = np.load(specdir / row.relpath / row.fname_spec.replace('welchspec', 'audio'))\n",
    "    try:\n",
    "        assert(len(spec) == len(df))\n",
    "        welchspecs.append(wspec)\n",
    "        praatspecs.append(pspec)\n",
    "        ltasspecs.append(lspec)\n",
    "        csvs.append(df)\n",
    "        auds.append(aud)\n",
    "        if freqs == {}:\n",
    "            freqs['welch'] = np.load(specdir / row.relpath / row.fname_spec.replace('welchspec', 'welchfreqs'))\n",
    "            freqs['ltas'] = np.load(specdir / row.relpath / row.fname_spec.replace('ltasspec', 'ltasfreqs'))\n",
    "            freqs['praatspec'] = np.load(specdir / row.relpath / row.fname_spec.replace('praatspec', 'praatfreqs'))\n",
    "    except AssertionError:\n",
    "        pass\n",
    "csvdf = pd.concat(csvs, axis='rows')\n",
    "welchspecarray = np.vstack(welchspecs)\n",
    "praatspecarray = np.vstack(praatspecs)\n",
    "ltasspecarray = np.vstack(ltasspecs)\n",
    "audioarray = np.vstack(auds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47953cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(len(csvdf) == len(welchspecarray) == len(audioarray))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5faaff",
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs['praatspec']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168c1757",
   "metadata": {},
   "outputs": [],
   "source": [
    "praatspecarray[idx][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12d86be",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 1\n",
    "specmaxidx = welchspecarray[idx,:].argmax()\n",
    "maxfreq = freqs['welch'][specmaxidx]\n",
    "print(f\"Spectrum of coda {csvdf.iloc[idx]['codaNUM2018']} at click {csvdf.iloc[idx]['clicknum']} for whale {csvdf.iloc[idx]['IDN']}; Max frequency: {maxfreq}\")\n",
    "fig, axs = plt.subplots(4)      \n",
    "axs[0].plot(audioarray[idx])\n",
    "axs[0].set_title = 'audio'\n",
    "axs[1].plot(freqs['welch'], 10*np.log10(welchspecarray[idx]/2e-5))\n",
    "axs[2].plot(freqs['welch'], welchspecarray[idx])\n",
    "axs[3].plot(freqs['praatspec'], 10*np.log10(np.abs(praatspecarray[idx][0])/2e-5))\n",
    "fig.tight_layout()\n",
    "audio = Audio(data=audioarray[idx], rate=resample_rate)\n",
    "display(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09b82ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(csvdf.iloc[idx].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d9aadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 2))\n",
    "plt.imshow(10*np.log10(specarray.T/2e-5));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05093e1c",
   "metadata": {},
   "source": [
    "## Textgrids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0a470c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tgdf = dir2df(tgdir, addcols='barename')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b24d6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tgdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Phonlab Python 3.11",
   "language": "python",
   "name": "python-3.11-phonlab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
